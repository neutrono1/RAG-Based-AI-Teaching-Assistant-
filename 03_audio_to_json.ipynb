{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmswOZY7O8WUoQAeVHq5lY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Audio to JSON (Transcription & Chunking)\n","\n","This notebook converts lecture audio files into structured JSON documents.\n","\n","Pipeline:\n","1. Load MP3 lecture audio files\n","2. Transcribe audio using OpenAI Whisper (large-v2)\n","3. Merge Whisper segments into RAG-optimized chunks\n","4. Store timestamps, lecture metadata, and text\n","5. Save output as reusable JSON files\n","\n","Chunking Strategy:\n","- Time-based chunking (15â€“25 seconds)\n","- Small overlap to preserve context\n","- Designed for embedding and retrieval performance\n"],"metadata":{"id":"gTZ7x4sH9Bvk"}},{"cell_type":"markdown","source":["### Imports & Paths"],"metadata":{"id":"vpQik9Na9KOv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHMbpuGu87TP"},"outputs":[],"source":["import os\n","import json\n","import whisper\n","from tqdm import tqdm\n"]},{"cell_type":"code","source":["BASE_DIR = \"/content/drive/MyDrive/RAG_BAS_PROJECT\"\n","AUDIO_DIR = os.path.join(BASE_DIR, \"AUDIOS\")\n","JSON_DIR = os.path.join(BASE_DIR, \"jsons\")\n","\n","os.makedirs(JSON_DIR, exist_ok=True)\n","\n","print(\"Directories ready\")\n"],"metadata":{"id":"9uTe_fIg9fdm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Whisper Model"],"metadata":{"id":"YDgi5zDQ9nwo"}},{"cell_type":"code","source":["model = whisper.load_model(\"large-v2\")\n","print(\"Whisper large-v2 model loaded\")\n"],"metadata":{"id":"0Po97qtA9kDW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Chunking Parameters\n","\n","- MAX_DURATION: Target chunk length (seconds)\n","- OVERLAP: Context overlap between chunks\n"],"metadata":{"id":"ig4A0ed-9ri5"}},{"cell_type":"code","source":["MAX_DURATION = 20   # seconds\n","OVERLAP = 3         # seconds\n"],"metadata":{"id":"0IxvlUnL9sM_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chunk Creation Function"],"metadata":{"id":"W_gl0OLl-ORX"}},{"cell_type":"code","source":["def create_chunks(segments, lecture_number, lecture_title):\n","    chunks = []\n","    buffer_text = []\n","    chunk_start = None\n","\n","    for seg in segments:\n","        if chunk_start is None:\n","            chunk_start = seg[\"start\"]\n","\n","        buffer_text.append(seg[\"text\"].strip())\n","        duration = seg[\"end\"] - chunk_start\n","\n","        if duration >= MAX_DURATION:\n","            chunks.append({\n","                \"Number\": lecture_number,\n","                \"Title\": lecture_title,\n","                \"Start\": round(chunk_start, 2),\n","                \"End\": round(seg[\"end\"], 2),\n","                \"Text\": \" \".join(buffer_text)\n","            })\n","\n","            # Overlap handling\n","            chunk_start = seg[\"end\"] - OVERLAP\n","            buffer_text = []\n","\n","    # Handle leftover text\n","    if buffer_text:\n","        chunks.append({\n","            \"Number\": lecture_number,\n","            \"Title\": lecture_title,\n","            \"Start\": round(chunk_start, 2),\n","            \"End\": round(segments[-1][\"end\"], 2),\n","            \"Text\": \" \".join(buffer_text)\n","        })\n","\n","    return chunks\n"],"metadata":{"id":"BPWXlMbj-MEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### List Audio Files"],"metadata":{"id":"OIuk0uSa_F_n"}},{"cell_type":"code","source":["audio_files = sorted([\n","    f for f in os.listdir(AUDIO_DIR)\n","    if f.endswith(\".mp3\")\n","])\n","\n","print(f\"Found {len(audio_files)} audio files\")\n"],"metadata":{"id":"UtkO2E-l-zo_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Transcribe & Save JSON"],"metadata":{"id":"NGAsuFmJ_Cto"}},{"cell_type":"code","source":["for audio in tqdm(audio_files):\n","    lecture_number = audio.split(\"_\")[0]\n","    lecture_title = audio.split(\"_\", 1)[1].replace(\".mp3\", \"\")\n","    audio_path = os.path.join(AUDIO_DIR, audio)\n","\n","    output_json_path = os.path.join(\n","        JSON_DIR,\n","        f\"{lecture_number}_{lecture_title}.json\"\n","    )\n","\n","    # Skip if already processed\n","    if os.path.exists(output_json_path):\n","        print(f\"Skipping (already exists): {lecture_number}_{lecture_title}\")\n","        continue\n","\n","    print(f\"\\nTranscribing: {audio}\")\n","\n","    result = model.transcribe(\n","        audio=audio_path,\n","        language=\"en\",\n","        task=\"transcribe\",\n","        word_timestamps=False\n","    )\n","\n","    chunks = create_chunks(\n","        segments=result[\"segments\"],\n","        lecture_number=lecture_number,\n","        lecture_title=lecture_title\n","    )\n","\n","    output = {\n","        \"lecture_number\": lecture_number,\n","        \"lecture_title\": lecture_title,\n","        \"full_text\": result[\"text\"],\n","        \"chunks\": chunks\n","    }\n","\n","    with open(output_json_path, \"w\") as f:\n","        json.dump(output, f, indent=2)\n","\n","    print(f\"Saved JSON: {output_json_path}\")\n"],"metadata":{"id":"rJsKkE_O-2Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"03_audio_to_json.ipynb completed successfully.\")\n"],"metadata":{"id":"qlkoe57b_Mxv"},"execution_count":null,"outputs":[]}]}