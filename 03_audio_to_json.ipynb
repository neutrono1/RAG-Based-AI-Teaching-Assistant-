{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTZ7x4sH9Bvk"
   },
   "source": [
    "# Audio to JSON (Transcription & Chunking)\n",
    "\n",
    "This notebook converts lecture audio files into structured JSON documents.\n",
    "\n",
    "Pipeline:\n",
    "1. Load MP3 lecture audio files\n",
    "2. Transcribe audio using OpenAI Whisper (large-v2)\n",
    "3. Merge Whisper segments into RAG-optimized chunks\n",
    "4. Store timestamps, lecture metadata, and text\n",
    "5. Save output as reusable JSON files\n",
    "\n",
    "Chunking Strategy:\n",
    "- Time-based chunking (15â€“25 seconds)\n",
    "- Small overlap to preserve context\n",
    "- Designed for embedding and retrieval performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpQik9Na9KOv"
   },
   "source": [
    "### Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHMbpuGu87TP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import whisper\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uTe_fIg9fdm"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/content/drive/MyDrive/RAG_BAS_PROJECT\"\n",
    "AUDIO_DIR = os.path.join(BASE_DIR, \"Audios\")\n",
    "JSON_DIR = os.path.join(BASE_DIR, \"jsons\")\n",
    "\n",
    "os.makedirs(JSON_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Directories ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDgi5zDQ9nwo"
   },
   "source": [
    "### Load Whisper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Po97qtA9kDW"
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large-v2\")\n",
    "print(\"Whisper large-v2 model loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig4A0ed-9ri5"
   },
   "source": [
    "## Chunking Parameters\n",
    "\n",
    "- MAX_DURATION: Target chunk length (seconds)\n",
    "- OVERLAP: Context overlap between chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IxvlUnL9sM_"
   },
   "outputs": [],
   "source": [
    "MAX_DURATION = 20   # seconds\n",
    "OVERLAP = 3         # seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_gl0OLl-ORX"
   },
   "source": [
    "### Chunk Creation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPWXlMbj-MEB"
   },
   "outputs": [],
   "source": [
    "def create_chunks(segments, lecture_number, lecture_title):\n",
    "    chunks = []\n",
    "    buffer_text = []\n",
    "    chunk_start = None\n",
    "\n",
    "    for seg in segments:\n",
    "        if chunk_start is None:\n",
    "            chunk_start = seg[\"start\"]\n",
    "\n",
    "        buffer_text.append(seg[\"text\"].strip())\n",
    "        duration = seg[\"end\"] - chunk_start\n",
    "\n",
    "        if duration >= MAX_DURATION:\n",
    "            chunks.append({\n",
    "                \"Number\": lecture_number,\n",
    "                \"Title\": lecture_title,\n",
    "                \"Start\": round(chunk_start, 2),\n",
    "                \"End\": round(seg[\"end\"], 2),\n",
    "                \"Text\": \" \".join(buffer_text)\n",
    "            })\n",
    "\n",
    "            # Overlap handling\n",
    "            chunk_start = seg[\"end\"] - OVERLAP\n",
    "            buffer_text = []\n",
    "\n",
    "    # Handle leftover text\n",
    "    if buffer_text:\n",
    "        chunks.append({\n",
    "            \"Number\": lecture_number,\n",
    "            \"Title\": lecture_title,\n",
    "            \"Start\": round(chunk_start, 2),\n",
    "            \"End\": round(segments[-1][\"end\"], 2),\n",
    "            \"Text\": \" \".join(buffer_text)\n",
    "        })\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIuk0uSa_F_n"
   },
   "source": [
    "#### List Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtkO2E-l-zo_"
   },
   "outputs": [],
   "source": [
    "audio_files = sorted([\n",
    "    f for f in os.listdir(AUDIO_DIR)\n",
    "    if f.endswith(\".mp3\")\n",
    "])\n",
    "\n",
    "print(f\"Found {len(audio_files)} audio files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGAsuFmJ_Cto"
   },
   "source": [
    "#### Transcribe & Save JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJsKkE_O-2Ws"
   },
   "outputs": [],
   "source": [
    "for audio in tqdm(audio_files):\n",
    "    lecture_number = audio.split(\"_\")[0]\n",
    "    lecture_title = audio.split(\"_\", 1)[1].replace(\".mp3\", \"\")\n",
    "    audio_path = os.path.join(AUDIO_DIR, audio)\n",
    "\n",
    "    output_json_path = os.path.join(\n",
    "        JSON_DIR,\n",
    "        f\"{lecture_number}_{lecture_title}.json\"\n",
    "    )\n",
    "\n",
    "    # Skip if already processed\n",
    "    if os.path.exists(output_json_path):\n",
    "        print(f\"Skipping (already exists): {lecture_number}_{lecture_title}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTranscribing: {audio}\")\n",
    "\n",
    "    result = model.transcribe(\n",
    "        audio=audio_path,\n",
    "        language=\"en\",\n",
    "        task=\"transcribe\",\n",
    "        word_timestamps=False\n",
    "    )\n",
    "\n",
    "    chunks = create_chunks(\n",
    "        segments=result[\"segments\"],\n",
    "        lecture_number=lecture_number,\n",
    "        lecture_title=lecture_title\n",
    "    )\n",
    "\n",
    "    output = {\n",
    "        \"lecture_number\": lecture_number,\n",
    "        \"lecture_title\": lecture_title,\n",
    "        \"full_text\": result[\"text\"],\n",
    "        \"chunks\": chunks\n",
    "    }\n",
    "\n",
    "    with open(output_json_path, \"w\") as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "\n",
    "    print(f\"Saved JSON: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlkoe57b_Mxv"
   },
   "outputs": [],
   "source": [
    "print(\"03_audio_to_json.ipynb completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmswOZY7O8WUoQAeVHq5lY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
